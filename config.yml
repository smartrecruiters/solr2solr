from:
  host: 'solr-applicants1-int'
  port: '8983'
  core: '/applicants_shard1_replica7'
  path: '/solr'

# copy destination
to:
  host: 'solr-applicants1-int'
  port: '8983'
  core: '/applicants'
  path: '/solr'

# this query will be executed against the "from" documents to select to documents to move
query:'appliedOn:[2013-01-01T23:59:59.999Z TO 2013-01-05T23:59:59.999Z]'
params:
  fl: 'candidate_id,hash_code_uuid'

update:
  key: ["candidate_id"]
  copyfield: ["hash_code_uuid"]

# number of rows per fetch.  Have to do some trial and error here to throttle this just right
# to get both a decent speed and keep safe from memory issues.  If duplicate is used, have to
# factor that in as well
rows: 150

throttle: 50

logQueries: true

# the number (0 based) of the first row to fetch.  Useful if a large copy operation fails midway
# and you need to start up again as some place other than the first record.
start: 0

# This'll allow you to multiply your data by simply taking each record, modifying the id field to be
# unique, and adding it an extra number of times to the index.  numberOfTimes = 2, means that each document
# will be added to the index 3 times total.
duplicate:
  enabled: false
  idField:'docid'
  numberOfTimes: 2

# Field you want to exclude
exclude: ["_version_"]

# When true copy is ignored and documents are copied verbatim
clone: true

# fields to straight copy over
copy:["*"]

# fields that get copied over, but get their names changed to something else
transform:[]

# brand new fields, great for filling in test data
# {name} is the name of the field and fabricate is the method called to create the test data
# it is passed the fields already created for the document, as well as number row the document is
# in processing
fabricate:[]